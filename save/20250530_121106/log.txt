model: hrnet_custom
description: (blocks 2, channels 32, module 1 1 2 1, res=[32, 16, 8, 4], 13분에 1에폭..?) data argumentation(AutoAugmentPolicy.CIFAR10), Adapt drop path, 

AMP_OPT_LEVEL: O1
BASE: ['']
DATA:
  BATCH_SIZE: 256
  CACHE_MODE: part
  DATASET: cifar
  DATA_PATH: 
  IMG_SIZE: 32
  INTERPOLATION: bicubic
  NUM_WORKERS: 4
  PIN_MEMORY: True
  ZIP_MODE: False
EVAL_MODE: False
LOCAL_RANK: 0
MODEL:
  DROP_PATH_RATE: 0.1
  DROP_RATE: 0.0
  HRNET:
    DROP_PATH_RATE: 0.2
    STAGE1:
      BLOCK: BOTTLENECK
      NUM_BLOCKS: [2]
      NUM_BRANCHES: 1
      NUM_CHANNELS: [64]
      NUM_MODULES: 1
    STAGE2:
      BLOCK: BASIC
      NUM_BLOCKS: [2, 2]
      NUM_BRANCHES: 2
      NUM_CHANNELS: [32, 64]
      NUM_MODULES: 1
    STAGE3:
      BLOCK: BASIC
      NUM_BLOCKS: [2, 2, 2]
      NUM_BRANCHES: 3
      NUM_CHANNELS: [32, 64, 128]
      NUM_MODULES: 2
    STAGE4:
      BLOCK: BASIC
      NUM_BLOCKS: [2, 2, 2, 2]
      NUM_BRANCHES: 4
      NUM_CHANNELS: [32, 64, 128, 256]
      NUM_MODULES: 1
  LABEL_SMOOTHING: 0.1
  NAME: hrnet_w18_small_v2
  NUM_CLASSES: 100
  RESUME: 
  RESUME_ONLY_MODEL: False
  TYPE: hrnet
OUTPUT: hrnet_w18_small_v2\default
PRINT_FREQ: 10
SAVE_FREQ: 1
SEED: 0
TAG: default
TEST:
  CROP: True
THROUGHPUT_MODE: False
TRAIN:
  ACCUMULATION_STEPS: 0
  AUTO_RESUME: True
  BASE_LR: 0.0005
  CLIP_GRAD: 5.0
  EPOCHS: 200
  LR_SCHEDULER:
    DECAY_EPOCHS: 30
    DECAY_RATE: 0.1
    NAME: cosine
  MIN_LR: 5e-06
  OPTIMIZER:
    BETAS: (0.9, 0.999)
    EPS: 1e-08
    MOMENTUM: 0.9
    NAME: adamw
  START_EPOCH: 0
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 20
  WARMUP_LR: 5e-07
  WEIGHT_DECAY: 0.05

Epoch [1/200] Train Loss: 4.1709, Train Acc: 6.69% | Valid Loss: 3.5428, Valid Acc: 15.11% | Early Stop Count: current patience : 0
